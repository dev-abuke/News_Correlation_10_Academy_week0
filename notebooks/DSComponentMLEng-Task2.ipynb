{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from keybert import KeyBERT\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader import NewsDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output File: news_output.csv\n",
      "Path: data\n",
      "News Data: rating.csv\n",
      "Traffic Data: trafiic.csv\n",
      "Domain Location Data: domains_location.csv\n"
     ]
    }
   ],
   "source": [
    "from src.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_loader = NewsDataLoader(cfg.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_news_df = news_data_loader.get_news_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'source_id', 'source_name', 'author', 'title',\n",
       "       'description', 'url', 'url_to_image', 'published_at', 'content',\n",
       "       'category', 'article', 'title_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns\n",
    "original_news_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id             0\n",
       "source_id          40585\n",
       "source_name            0\n",
       "author              2163\n",
       "title                  0\n",
       "description           10\n",
       "url                    0\n",
       "url_to_image        3451\n",
       "published_at           0\n",
       "content                0\n",
       "category              21\n",
       "article                0\n",
       "title_sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_news_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58356\n",
      "58356\n"
     ]
    }
   ],
   "source": [
    "test_content = original_news_df['content']\n",
    "test_title = original_news_df['title']\n",
    "print(test_title.count())\n",
    "print(test_content.count())\n",
    "#cleantxt = utils.clean_text(test_content)\n",
    "#print('The Cleaned Text is: \\n')\n",
    "#print(cleantxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is grat but we need vectorizers to get the keywords that sound grammatically correct\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_keywords = kw_model.extract_keywords(docs=test_title, vectorizer=KeyphraseCountVectorizer())\n",
    "content_keywords = kw_model.extract_keywords(docs=test_content, vectorizer=KeyphraseCountVectorizer())\n",
    "\n",
    "def flatten_and_extract_keywords(list_of_tuples):\n",
    "    return [item[0] for item in list_of_tuples]\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1) + len(set2) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "# Calculate Jaccard similarity for each pair of lists\n",
    "similarities = []\n",
    "for title_list, content_list in zip(title_keywords, content_keywords):\n",
    "    title_keywords_flat = flatten_and_extract_keywords(title_list)\n",
    "    content_keywords_flat = flatten_and_extract_keywords(content_list)\n",
    "    similarity = jaccard_similarity(title_keywords_flat, content_keywords_flat)\n",
    "    similarities.append(similarity)\n",
    "    print(f\"Jaccard similarity: {similarity} for title keywords: {title_keywords_flat} and content keywords: {content_keywords_flat}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(similarities)), similarities)\n",
    "plt.xlabel('Pair Index')\n",
    "plt.ylabel('Jaccard Similarity')\n",
    "plt.title('Jaccard Similarity between Title and Content Keywords')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
