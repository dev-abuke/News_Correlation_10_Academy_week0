{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loader import NewsDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output File: news_output.csv\n",
      "Path: data\n",
      "News Data: rating.csv\n",
      "Traffic Data: trafiic.csv\n",
      "Domain Location Data: domains_location.csv\n"
     ]
    }
   ],
   "source": [
    "from src.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_loader = NewsDataLoader(cfg.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get news csv file\n",
    "news = news_data_loader.get_news()\n",
    "\n",
    "# get traffic csv file\n",
    "traffic = news_data_loader.get_traffic()\n",
    "\n",
    "# get domain location data csv file\n",
    "domain = news_data_loader.get_domain_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>url_to_image</th>\n",
       "      <th>published_at</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>article</th>\n",
       "      <th>title_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>Elizabeth Brownfield, Contributor, \\n Elizabet...</td>\n",
       "      <td>superstar chef yannick alléno brings refined f...</td>\n",
       "      <td>Now open in Mayfair at Four Seasons Hotel Lond...</td>\n",
       "      <td>https://www.forbes.com/sites/elizabethbrownfie...</td>\n",
       "      <td>https://imageio.forbes.com/specials-images/ima...</td>\n",
       "      <td>2023-11-01 03:27:21.000000</td>\n",
       "      <td>Pavyllon London, at Four Seasons Hotel London ...</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>pavyllon london, at four seasons hotel london ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nice claim top spot in ligue 1 with late win a...</td>\n",
       "      <td>Nice moved into provisional first place in the...</td>\n",
       "      <td>https://www.channelnewsasia.com/sport/nice-cla...</td>\n",
       "      <td>https://onecms-res.cloudinary.com/image/upload...</td>\n",
       "      <td>2023-10-27 21:28:48.000000</td>\n",
       "      <td>Nice moved into provisional first place in the...</td>\n",
       "      <td>Monaco</td>\n",
       "      <td>nice moved into provisional first place in the...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81694</td>\n",
       "      <td>time</td>\n",
       "      <td>Time</td>\n",
       "      <td>Christina Larson / AP</td>\n",
       "      <td>amphibians are the world’s most vulnerable spe...</td>\n",
       "      <td>The world’s frogs, salamanders, newts, and oth...</td>\n",
       "      <td>https://time.com/6320467/amphibians-most-vulne...</td>\n",
       "      <td>https://api.time.com/wp-content/uploads/2023/1...</td>\n",
       "      <td>2023-10-04 17:36:18.000000</td>\n",
       "      <td>The worlds frogs, salamanders, newts and other...</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>the world’s frogs, salamanders, newts and othe...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phys.Org</td>\n",
       "      <td>Sara Schmidt</td>\n",
       "      <td>image: rusty red waters in madagascar</td>\n",
       "      <td>Iron-rich sediment colors the red-orange water...</td>\n",
       "      <td>https://phys.org/news/2023-10-image-rusty-red-...</td>\n",
       "      <td>https://scx2.b-cdn.net/gfx/news/2023/image-rus...</td>\n",
       "      <td>2023-10-31 18:04:02.000000</td>\n",
       "      <td>Iron-rich sediment colors the red-orange water...</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>iron-rich sediment colors the red-orange water...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Trends</td>\n",
       "      <td>Jason Struss</td>\n",
       "      <td>everything leaving max (formerly hbo max) in n...</td>\n",
       "      <td>From Gangs of London to Fear the Walking Dead ...</td>\n",
       "      <td>https://www.digitaltrends.com/movies/everythin...</td>\n",
       "      <td>https://www.digitaltrends.com/wp-content/uploa...</td>\n",
       "      <td>2023-10-23 23:09:18.000000</td>\n",
       "      <td>Everything ends. No, I’m not having an existen...</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>everything ends. no, i’m not having an existen...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id source_id     source_name  \\\n",
       "0       81664       NaN          Forbes   \n",
       "1       81667       NaN             CNA   \n",
       "2       81694      time            Time   \n",
       "3       81695       NaN        Phys.Org   \n",
       "4       81703       NaN  Digital Trends   \n",
       "\n",
       "                                              author  \\\n",
       "0  Elizabeth Brownfield, Contributor, \\n Elizabet...   \n",
       "1                                                NaN   \n",
       "2                              Christina Larson / AP   \n",
       "3                                       Sara Schmidt   \n",
       "4                                       Jason Struss   \n",
       "\n",
       "                                               title  \\\n",
       "0  superstar chef yannick alléno brings refined f...   \n",
       "1  nice claim top spot in ligue 1 with late win a...   \n",
       "2  amphibians are the world’s most vulnerable spe...   \n",
       "3              image: rusty red waters in madagascar   \n",
       "4  everything leaving max (formerly hbo max) in n...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Now open in Mayfair at Four Seasons Hotel Lond...   \n",
       "1  Nice moved into provisional first place in the...   \n",
       "2  The world’s frogs, salamanders, newts, and oth...   \n",
       "3  Iron-rich sediment colors the red-orange water...   \n",
       "4  From Gangs of London to Fear the Walking Dead ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.forbes.com/sites/elizabethbrownfie...   \n",
       "1  https://www.channelnewsasia.com/sport/nice-cla...   \n",
       "2  https://time.com/6320467/amphibians-most-vulne...   \n",
       "3  https://phys.org/news/2023-10-image-rusty-red-...   \n",
       "4  https://www.digitaltrends.com/movies/everythin...   \n",
       "\n",
       "                                        url_to_image  \\\n",
       "0  https://imageio.forbes.com/specials-images/ima...   \n",
       "1  https://onecms-res.cloudinary.com/image/upload...   \n",
       "2  https://api.time.com/wp-content/uploads/2023/1...   \n",
       "3  https://scx2.b-cdn.net/gfx/news/2023/image-rus...   \n",
       "4  https://www.digitaltrends.com/wp-content/uploa...   \n",
       "\n",
       "                 published_at  \\\n",
       "0  2023-11-01 03:27:21.000000   \n",
       "1  2023-10-27 21:28:48.000000   \n",
       "2  2023-10-04 17:36:18.000000   \n",
       "3  2023-10-31 18:04:02.000000   \n",
       "4  2023-10-23 23:09:18.000000   \n",
       "\n",
       "                                             content    category  \\\n",
       "0  Pavyllon London, at Four Seasons Hotel London ...      Monaco   \n",
       "1  Nice moved into provisional first place in the...      Monaco   \n",
       "2  The worlds frogs, salamanders, newts and other...  Madagascar   \n",
       "3  Iron-rich sediment colors the red-orange water...  Madagascar   \n",
       "4  Everything ends. No, I’m not having an existen...  Madagascar   \n",
       "\n",
       "                                             article title_sentiment  \n",
       "0  pavyllon london, at four seasons hotel london ...         Neutral  \n",
       "1  nice moved into provisional first place in the...        Positive  \n",
       "2  the world’s frogs, salamanders, newts and othe...        Negative  \n",
       "3  iron-rich sediment colors the red-orange water...         Neutral  \n",
       "4  everything ends. no, i’m not having an existen...         Neutral  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58356 entries, 0 to 58355\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   article_id       58356 non-null  int64 \n",
      " 1   source_id        17771 non-null  object\n",
      " 2   source_name      58356 non-null  object\n",
      " 3   author           56193 non-null  object\n",
      " 4   title            58356 non-null  object\n",
      " 5   description      58346 non-null  object\n",
      " 6   url              58356 non-null  object\n",
      " 7   url_to_image     54905 non-null  object\n",
      " 8   published_at     58356 non-null  object\n",
      " 9   content          58356 non-null  object\n",
      " 10  category         58335 non-null  object\n",
      " 11  article          58356 non-null  object\n",
      " 12  title_sentiment  58356 non-null  object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id             0\n",
       "source_id          40585\n",
       "source_name            0\n",
       "author              2163\n",
       "title                  0\n",
       "description           10\n",
       "url                    0\n",
       "url_to_image        3451\n",
       "published_at           0\n",
       "content                0\n",
       "category              21\n",
       "article                0\n",
       "title_sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of articles per source_name\n",
    "article_counts = df['source_name'].value_counts()\n",
    "\n",
    "# Get the top 10 websites\n",
    "top_10_websites = article_counts.head(10)\n",
    "\n",
    "# Get the bottom 10 websites\n",
    "bottom_10_websites = article_counts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 websites with the largest count of news articles:\n",
      "ETF Daily News        16746\n",
      "The Times of India     7504\n",
      "GlobeNewswire          5423\n",
      "Globalsecurity.org     3119\n",
      "Forbes                 2784\n",
      "BBC News               2113\n",
      "ABC News               2058\n",
      "Business Insider       2034\n",
      "The Punch              1800\n",
      "Al Jazeera English     1664\n",
      "Name: source_name, dtype: int64\n",
      "\n",
      "Bottom 10 websites with the smallest count of news articles:\n",
      "CNA                            674\n",
      "Time                           600\n",
      "Android Central                522\n",
      "Gizmodo.com                    388\n",
      "ReadWrite                      324\n",
      "Euronews                       286\n",
      "Wired                          270\n",
      "CNN                            267\n",
      "The Verge                      214\n",
      "AllAfrica - Top Africa News     20\n",
      "Name: source_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 websites with the largest count of news articles:\")\n",
    "print(top_10_websites)\n",
    "print(\"\\nBottom 10 websites with the smallest count of news articles:\")\n",
    "print(bottom_10_websites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns we can get from the news data<br>\n",
    "\n",
    "article_id,\n",
    "source_id,\n",
    "source_name,\n",
    "author,\n",
    "title,\n",
    "description,\n",
    "url,\n",
    "url_to_image,\n",
    "published_at,\n",
    "content,\n",
    "category,\n",
    "article,\n",
    "title_sentiment,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a single slack message, we can get <br>\n",
    "\n",
    "1. The message<br>\n",
    "2. Type (message, file, link, etc)<br>\n",
    "3. The sender_id (assigned by slack)<br>\n",
    "4. The time the message was sent<br>\n",
    "5. The team (i don't know what that is now)<br>\n",
    "6. The type of the message (broadcast message, inhouse, just messgae)<br>\n",
    "7. The thread the message generated (from here we can go):<br>\n",
    "    7.1 Text/content of the message<br>\n",
    "    7.2 The thread time of the message<br>\n",
    "    7.3 The thread count (reply count)<br>\n",
    "    7.4 The number of user that reply the message (count of users that participated in the thread)<br>\n",
    "    7.5 The time the last thread message was sent <br>\n",
    "    7.6 The users that participated in the thread (their ids are stored as well)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all json file in all-weeks8-9\n",
    "def slack_parser(path_channel):\n",
    "    \"\"\" parse slack data to extract useful informations from the json file\n",
    "        step of execution\n",
    "        1. Import the required modules\n",
    "        2. read all json file from the provided path\n",
    "        3. combine all json files in the provided path\n",
    "        4. extract all required informations from the slack data\n",
    "        5. convert to dataframe and merge all\n",
    "        6. reset the index and return dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # specify path to get json files\n",
    "    combined = []\n",
    "    for json_file in glob.glob(f\"{path_channel}*.json\"):\n",
    "        with open(json_file, 'r', encoding=\"utf8\") as slack_data:\n",
    "            combined.append(slack_data)\n",
    "\n",
    "    # loop through all json files and extract required informations\n",
    "    dflist = []\n",
    "    for slack_data in combined:\n",
    "\n",
    "        msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st, reply_users, \\\n",
    "        reply_count, reply_users_count, tm_thread_end = [],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "        for row in slack_data:\n",
    "            if 'bot_id' in row.keys():\n",
    "                continue\n",
    "            else:\n",
    "                msg_type.append(row['type'])\n",
    "                msg_content.append(row['text'])\n",
    "                if 'user_profile' in row.keys(): sender_id.append(row['user_profile']['real_name'])\n",
    "                else: sender_id.append('Not provided')\n",
    "                time_msg.append(row['ts'])\n",
    "                if 'blocks' in row.keys() and len(row['blocks'][0]['elements'][0]['elements']) != 0 :\n",
    "                     msg_dist.append(row['blocks'][0]['elements'][0]['elements'][0]['type'])\n",
    "                else: msg_dist.append('reshared')\n",
    "                if 'thread_ts' in row.keys():\n",
    "                    time_thread_st.append(row['thread_ts'])\n",
    "                else:\n",
    "                    time_thread_st.append(0)\n",
    "                if 'reply_users' in row.keys(): reply_users.append(\",\".join(row['reply_users'])) \n",
    "                else:    reply_users.append(0)\n",
    "                if 'reply_count' in row.keys():\n",
    "                    reply_count.append(row['reply_count'])\n",
    "                    reply_users_count.append(row['reply_users_count'])\n",
    "                    tm_thread_end.append(row['latest_reply'])\n",
    "                else:\n",
    "                    reply_count.append(0)\n",
    "                    reply_users_count.append(0)\n",
    "                    tm_thread_end.append(0)\n",
    "        data = zip(msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st,\n",
    "         reply_count, reply_users_count, reply_users, tm_thread_end)\n",
    "        columns = ['msg_type', 'msg_content', 'sender_name', 'msg_sent_time', 'msg_dist_type',\n",
    "         'time_thread_start', 'reply_count', 'reply_users_count', 'reply_users', 'tm_thread_end']\n",
    "\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        df = df[df['sender_name'] != 'Not provided']\n",
    "        dflist.append(df)\n",
    "\n",
    "    dfall = pd.concat(dflist, ignore_index=True)\n",
    "    dfall['channel'] = path_channel.split('/')[-1].split('.')[0]        \n",
    "    dfall = dfall.reset_index(drop=True)\n",
    "    \n",
    "    return dfall\n",
    "\n",
    "\n",
    "def parse_slack_reaction(path, channel):\n",
    "    \"\"\"get reactions\"\"\"\n",
    "    dfall_reaction = pd.DataFrame()\n",
    "    combined = []\n",
    "    for json_file in glob.glob(f\"{path}*.json\"):\n",
    "        with open(json_file, 'r') as slack_data:\n",
    "            combined.append(slack_data)\n",
    "\n",
    "    reaction_name, reaction_count, reaction_users, msg, user_id = [], [], [], [], []\n",
    "\n",
    "    for k in combined:\n",
    "        slack_data = json.load(open(k.name, 'r', encoding=\"utf-8\"))\n",
    "        \n",
    "        for i_count, i in enumerate(slack_data):\n",
    "            if 'reactions' in i.keys():\n",
    "                for j in range(len(i['reactions'])):\n",
    "                    msg.append(i['text'])\n",
    "                    user_id.append(i['user'])\n",
    "                    reaction_name.append(i['reactions'][j]['name'])\n",
    "                    reaction_count.append(i['reactions'][j]['count'])\n",
    "                    reaction_users.append(\",\".join(i['reactions'][j]['users']))\n",
    "                \n",
    "    data_reaction = zip(reaction_name, reaction_count, reaction_users, msg, user_id)\n",
    "    columns_reaction = ['reaction_name', 'reaction_count', 'reaction_users_count', 'message', 'user_id']\n",
    "    df_reaction = pd.DataFrame(data=data_reaction, columns=columns_reaction)\n",
    "    df_reaction['channel'] = channel\n",
    "    return df_reaction\n",
    "\n",
    "def get_community_participation(path):\n",
    "    \"\"\" specify path to get json files\"\"\"\n",
    "    combined = []\n",
    "    comm_dict = {}\n",
    "    for json_file in glob.glob(f\"{path}*.json\"):\n",
    "        with open(json_file, 'r') as slack_data:\n",
    "            combined.append(slack_data)\n",
    "    # print(f\"Total json files is {len(combined)}\")\n",
    "    for i in combined:\n",
    "        a = json.load(open(i.name, 'r', encoding='utf-8'))\n",
    "\n",
    "        for msg in a:\n",
    "            if 'replies' in msg.keys():\n",
    "                for i in msg['replies']:\n",
    "                    comm_dict[i['user']] = comm_dict.get(i['user'], 0)+1\n",
    "    return comm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2_timestamp(column, data):\n",
    "    \"\"\"convert from unix time to readable timestamp\n",
    "        args: column: columns that needs to be converted to timestamp\n",
    "                data: data that has the specified column\n",
    "    \"\"\"\n",
    "    if column in data.columns.values:\n",
    "        timestamp_ = []\n",
    "        for time_unix in data[column]:\n",
    "            if time_unix == 0:\n",
    "                timestamp_.append(0)\n",
    "            else:\n",
    "                a = datetime.datetime.fromtimestamp(float(time_unix))\n",
    "                timestamp_.append(a.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        return timestamp_\n",
    "    else: \n",
    "        print(f\"{column} not in data\")\n",
    "\n",
    "def get_tagged_users(df):\n",
    "    \"\"\"get all @ in the messages\"\"\"\n",
    "\n",
    "    return df['msg_content'].map(lambda x: re.findall(r'@U\\w+', x))\n",
    "\n",
    "\n",
    "    \n",
    "def map_userid_2_realname(user_profile: dict, comm_dict: dict, plot=False):\n",
    "    \"\"\"\n",
    "    map slack_id to realnames\n",
    "    user_profile: a dictionary that contains users info such as real_names\n",
    "    comm_dict: a dictionary that contains slack_id and total_message sent by that slack_id\n",
    "    \"\"\"\n",
    "    user_dict = {} # to store the id\n",
    "    real_name = [] # to store the real name\n",
    "    ac_comm_dict = {} # to store the mapping\n",
    "    count = 0\n",
    "    # collect all the real names\n",
    "    for i in range(len(user_profile['profile'])):\n",
    "        real_name.append(dict(user_profile['profile'])[i]['real_name'])\n",
    "\n",
    "    # loop the slack ids\n",
    "    for i in user_profile['id']:\n",
    "        user_dict[i] = real_name[count]\n",
    "        count += 1\n",
    "\n",
    "    # to store mapping\n",
    "    for i in comm_dict:\n",
    "        if i in user_dict:\n",
    "            ac_comm_dict[user_dict[i]] = comm_dict[i]\n",
    "\n",
    "    ac_comm_dict = pd.DataFrame(data= zip(ac_comm_dict.keys(), ac_comm_dict.values()),\n",
    "    columns=['LearnerName', '# of Msg sent in Threads']).sort_values(by='# of Msg sent in Threads', ascending=False)\n",
    "    \n",
    "    if plot:\n",
    "        ac_comm_dict.plot.bar(figsize=(15, 7.5), x='LearnerName', y='# of Msg sent in Threads')\n",
    "        plt.title('Student based on Message sent in thread', size=20)\n",
    "        \n",
    "    return ac_comm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_20_user(data, channel='Random'):\n",
    "    \"\"\"get user with the highest number of message sent to any channel\"\"\"\n",
    "\n",
    "    data['sender_name'].value_counts()[:20].plot.bar(figsize=(15, 7.5))\n",
    "    plt.title(f'Top 20 Message Senders in #{channel} channels', size=15, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.xticks(size=12); plt.yticks(size=12);\n",
    "    plt.show()\n",
    "\n",
    "    data['sender_name'].value_counts()[-10:].plot.bar(figsize=(15, 7.5))\n",
    "    plt.title(f'Bottom 10 Message Senders in #{channel} channels', size=15, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.xticks(size=12); plt.yticks(size=12);\n",
    "    plt.show()\n",
    "\n",
    "def draw_avg_reply_count(data, channel='Random'):\n",
    "    \"\"\"who commands many reply?\"\"\"\n",
    "\n",
    "    data.groupby('sender_name')['reply_count'].mean().sort_values(ascending=False)[:20]\\\n",
    "        .plot(kind='bar', figsize=(15,7.5));\n",
    "    plt.title(f'Average Number of reply count per Sender in #{channel}', size=20, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()\n",
    "\n",
    "def draw_avg_reply_users_count(data, channel='Random'):\n",
    "    \"\"\"who commands many user reply?\"\"\"\n",
    "\n",
    "    data.groupby('sender_name')['reply_users_count'].mean().sort_values(ascending=False)[:20].plot(kind='bar',\n",
    "     figsize=(15,7.5));\n",
    "    plt.title(f'Average Number of reply user count per Sender in #{channel}', size=20, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()\n",
    "\n",
    "def draw_wordcloud(msg_content, week):    \n",
    "    # word cloud visualization\n",
    "    allWords = ' '.join([twts for twts in msg_content])\n",
    "    wordCloud = WordCloud(background_color='#975429', width=500, height=300, random_state=21, max_words=500, mode='RGBA',\n",
    "                            max_font_size=140, stopwords=stopwords.words('english')).generate(allWords)\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'WordCloud for {week}', size=30)\n",
    "    plt.show()\n",
    "\n",
    "def draw_user_reaction(data, channel='General'):\n",
    "    data.groupby('sender_name')[['reply_count', 'reply_users_count']].sum()\\\n",
    "        .sort_values(by='reply_count',ascending=False)[:10].plot(kind='bar', figsize=(15, 7.5))\n",
    "    plt.title(f'User with the most reaction in #{channel}', size=25);\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight Extraction\n",
    "\n",
    "Below are some useful questions to answer. Feel free to explore to answer other interesting questions that may be of help to get insight about student's behaviour, need, and future performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which user has the highest number of reply counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reply counts per user per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the time range of the day that most messages are sent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kind of messages are replied faster than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between # of messages and # of reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify messages into different categories such as questions, answers, comments, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which users got the most reactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model topics mentioned in the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the topics that got the most reactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harder questions to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on messages, reactions, references shared, and other relevant data such as classification of questions into techical question, comment, answer, aorder stu the python, statistics, and sql skill level of a user?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
